{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94af66-957d-446b-bca6-1f1ba70ac8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbimporter\n",
    "\n",
    "root = os.getcwd().split(\"survival_analysis\")[0]\n",
    "os.chdir(root + \"survival_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ffd6c-ac5b-4f07-9012-ed85b8bf9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13161e6c-051d-44d3-9c4e-436e582b9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets.survival_net import SurvivalNN\n",
    "from nets.cox_nn import CoxNN, CoxTimeDependentNN\n",
    "from utils.nn_utils import NetTrainer, WeightedBCELoss, SuMoLoss\n",
    "from nets.monotone_module import MonotonicIncreasingVectorNet, MonotonicIncreasingNet\n",
    "from data_and_preprocessing.dfs_generator import Gbsg2Generator, RecurGenerator, LymphGenerator, CaliforniaHousingGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050707dc-837a-4b76-abfa-577b44c08441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_postfix(sumo):\n",
    "    if sumo:\n",
    "        return \"SUMO\"\n",
    "    return \"BCE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a433f-fbd9-47c3-a7da-6e99b138c0b8",
   "metadata": {},
   "source": [
    "# Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d68b70-708a-4e7e-b92d-8ffe437915c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_total_todo = 5\n",
    "n_training_steps = 200000\n",
    "model_via_moving_average_on_validation = 512"
   ]
  },
  {
   "cell_type": "raw",
   "id": "536d31b2-beaa-4863-9f14-4957c9dad30e",
   "metadata": {},
   "source": [
    "glob_total_todo = 2\n",
    "n_training_steps = 17\n",
    "model_via_moving_average_on_validation = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f5623-5040-4ea1-b084-eb6cdcd6f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bce_weight(dataset_name):\n",
    "    if dataset_name == \"gbsg2\":\n",
    "        return 0.71\n",
    "\n",
    "    if dataset_name == 'recur':\n",
    "        return 0.85\n",
    "\n",
    "    if dataset_name == 'lymph':\n",
    "        return 0.86\n",
    "\n",
    "    if dataset_name == 'california':\n",
    "        return 0.53\n",
    "\n",
    "    raise ValueError(\"Bad dataset name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b93fc-9f3b-4650-b579-09102d17492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bce_std_factor(dataset_name):\n",
    "    if dataset_name == \"gbsg2\":\n",
    "        return 0.82\n",
    "\n",
    "    if dataset_name == 'recur':\n",
    "        return 0.96\n",
    "\n",
    "    if dataset_name == 'lymph':\n",
    "        return 0.79\n",
    "\n",
    "    if dataset_name == 'california':\n",
    "        return 0.5\n",
    "\n",
    "    raise ValueError(\"Bad dataset name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ad64b-1035-4463-bb5e-98057f7a6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sumo_weight(dataset_name):\n",
    "    if dataset_name == \"gbsg2\":\n",
    "        return 2.7\n",
    "\n",
    "    if dataset_name == 'recur':\n",
    "        return 0.87\n",
    "\n",
    "    if dataset_name == 'lymph':\n",
    "        return 3.44\n",
    "\n",
    "    if dataset_name == 'california':\n",
    "        return 0.89\n",
    "\n",
    "    raise ValueError(\"Bad dataset name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c361908-9a84-44df-8e3c-dffa18edb742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sumo_weight_decay(dataset_name, model_name):\n",
    "    if model_name not in [\"CoxNN\", \"CoxTimeDependentNN\"]:\n",
    "        return 0\n",
    "\n",
    "    if dataset_name == \"gbsg2\":\n",
    "        return 0.005\n",
    "\n",
    "    if dataset_name == 'recur':\n",
    "        return 0.001\n",
    "\n",
    "    if dataset_name == 'lymph':\n",
    "        return 0.004\n",
    "\n",
    "    if dataset_name == 'california':\n",
    "        return 0.009\n",
    "\n",
    "    assert False, f\"Bad inputs in get_sumo_weight_decay {dataset_name=}, {model_name=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426553f-9766-47ba-9e06-1cbe0915bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bce_weight_decay(dataset_name, model_name):\n",
    "    if model_name not in [\"CoxNN\", \"CoxTimeDependentNN\"]:\n",
    "        return 0\n",
    "\n",
    "    if dataset_name == \"gbsg2\":\n",
    "        return 0.02\n",
    "\n",
    "    if dataset_name == 'recur':\n",
    "        return 0.001\n",
    "\n",
    "    if dataset_name == 'lymph':\n",
    "        return 0.002\n",
    "\n",
    "    if dataset_name == 'california':\n",
    "        return 0.005\n",
    "\n",
    "    assert False, f\"Bad inputs in get_bce_weight_decay {dataset_name=}, {model_name=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95287978-09ad-4b7a-badc-2b2feddfd8e5",
   "metadata": {},
   "source": [
    "# General training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b783c23-c692-4f0a-a842-9e62a41adf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand():\n",
    "    return np.random.randint(100000, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc3df6-c335-4a2c-a082-85caca215084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(df_generator, sumo):\n",
    "    dataset_name = df_generator.name\n",
    "    if sumo:\n",
    "        weight = get_sumo_weight(dataset_name)\n",
    "        return SuMoLoss(weight=weight)\n",
    "\n",
    "    weight = get_bce_weight(dataset_name)\n",
    "\n",
    "    σ_gaussian_delta_factor = get_bce_std_factor(dataset_name)\n",
    "    σ_gaussian_delta = σ_gaussian_delta_factor * df_generator.max_horizon\n",
    "    return WeightedBCELoss(σ_gaussian_delta=σ_gaussian_delta, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb41bf-0702-49fc-8367-66dad3c28af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_trainer(dataset_name, weight_decay, sumo):\n",
    "    df_generator = pickle.load(open(f\"data_and_preprocessing/df_generator_{dataset_name}.pickle\", \"rb\" ))\n",
    "    criterion = get_criterion(df_generator, sumo)\n",
    "\n",
    "    return NetTrainer(\n",
    "        df_generator=df_generator,\n",
    "        patience_factor=16,\n",
    "        batch_size=8,\n",
    "        model_via_moving_average_on_validation=model_via_moving_average_on_validation,\n",
    "        criterion=criterion,\n",
    "        clip=1,\n",
    "        lr=1e-3,\n",
    "        weight_decay=weight_decay,\n",
    "        n_training_steps=n_training_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe55cfa-f4d4-4897-9b59-f335a8d5a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, net_trainer, rand):\n",
    "    print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "    name = f\"{model_name}_{rand}\"\n",
    "\n",
    "    if how_many_left_to_do(net_trainer.df_generator.name, model_name, total_todo=5) < 0:\n",
    "        return\n",
    "\n",
    "    model, best_val_score, model_dict = net_trainer.train_and_save(name=name, model=model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fe951-32a6-4a71-bd1b-e17c6ce9cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(dataset_name, get_model, sumo):\n",
    "    model_name = get_model(None, only_name=True)\n",
    "\n",
    "    if sumo:\n",
    "        weight_decay = get_sumo_weight_decay(dataset_name, model_name)\n",
    "    else:\n",
    "        weight_decay = get_bce_weight_decay(dataset_name, model_name)\n",
    "\n",
    "    model_name = get_model(None, only_name=True) +  \"-\" + get_loss_postfix(sumo)\n",
    "    rand = get_rand()\n",
    "\n",
    "    dummy_file_path = f'trained_models/{dataset_name}/{model_name}_{rand}.dummy'\n",
    "    open(dummy_file_path, 'wb').close()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        try:\n",
    "            net_trainer = get_net_trainer(dataset_name=dataset_name, weight_decay=weight_decay, sumo=sumo)\n",
    "            model, _ = get_model(net_trainer)\n",
    "            model = train(model, model_name=model_name, net_trainer=net_trainer, rand=rand)\n",
    "            done = True\n",
    "            os.remove(dummy_file_path)\n",
    "        except:\n",
    "            print(\"Training failed for:\", dummy_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d92b5a-1a83-4e0f-a458-fe1b03333fd5",
   "metadata": {},
   "source": [
    "# Cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b53197-3988-4ff9-bb9e-d41409b6daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CoxNN(net_trainer, only_name=False):\n",
    "    model_name = \"CoxNN\"\n",
    "    if only_name:\n",
    "        return model_name\n",
    "\n",
    "    monotonic_increasing_net = MonotonicIncreasingNet(latent_sizes=[32]*5)\n",
    "    model = CoxNN(\n",
    "        n_input_features=net_trainer.n_input_features,\n",
    "        monotonic_increasing_net=monotonic_increasing_net,\n",
    "        t_scaling=net_trainer.horizon,\n",
    "    )\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af4b79c-e88f-4a83-bdf1-13ca6d798e9e",
   "metadata": {},
   "source": [
    "# CoxTimeDependentNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58640533-91dc-47b3-9501-a7ef3813e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CoxTimeDependentNN(net_trainer, only_name=False):\n",
    "    model_name = \"CoxTimeDependentNN\"\n",
    "    if only_name:\n",
    "        return model_name\n",
    "\n",
    "    monotonic_increasing_net = MonotonicIncreasingNet(latent_sizes=[32]*5)\n",
    "    monotonic_increasing_net_coefficients = MonotonicIncreasingVectorNet(latent_sizes=[32]*5 + [net_trainer.n_input_features,])\n",
    "\n",
    "    model = CoxTimeDependentNN(\n",
    "        n_input_features=net_trainer.n_input_features,\n",
    "        monotonic_increasing_net_baseline=monotonic_increasing_net,\n",
    "        monotonic_increasing_net_coefficients=monotonic_increasing_net_coefficients,\n",
    "        t_scaling=net_trainer.horizon,\n",
    "    )\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff147ade-4246-4d33-8056-c9472d723902",
   "metadata": {},
   "source": [
    "# SurvivalNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede13c0-66e5-4e84-8c47-1e8e89805cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SurvivalNN(net_trainer, only_name=False):\n",
    "    model_name = \"SurvivalNN\"\n",
    "    if only_name:\n",
    "        return model_name\n",
    "\n",
    "    model = SurvivalNN(\n",
    "        n_input_features=net_trainer.n_input_features,\n",
    "        n_latent_features=32,\n",
    "        t_scaling=net_trainer.horizon\n",
    "    )\n",
    "    return model, model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1628caa-7fd5-434d-a4f5-f297c0695e2e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2b22d-942b-4576-b4f8-4b78d0064882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_getters():\n",
    "    getter_fcts = [\n",
    "        get_CoxNN, get_CoxTimeDependentNN, get_SurvivalNN,\n",
    "    ]\n",
    "\n",
    "    dict_getter_fcts = {\n",
    "        getter_fct(None, only_name=True): getter_fct for getter_fct in getter_fcts\n",
    "    }\n",
    "\n",
    "    return dict_getter_fcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2916a9-bc61-494b-8f2e-0ce9e97352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_names():\n",
    "    return [\"gbsg2\", \"recur\", \"lymph\", \"california\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14df7e-2d47-439c-8247-2292b0148cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_model_dataset_combinations(dataset_names):\n",
    "    combis = []\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "        for model_name, get_model in get_model_getters().items():\n",
    "            combis.append((dataset_name, model_name))\n",
    "\n",
    "    return combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84df88-3fab-4fce-a571-657b1c1941e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_left_to_do(dataset_name, model_name, total_todo):\n",
    "    files_in_folder = glob.glob(f'trained_models/{dataset_name}/*')\n",
    "    model_files_in_folder = [file_name for file_name in files_in_folder if f\"{model_name}_\" in file_name]\n",
    "    return total_todo - len(model_files_in_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c82f19-ac48-480f-92a5-92c2351af322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_todo_model_dataset_combinations(dataset_names, sumo, total_todo=glob_total_todo):\n",
    "    all_combis = get_all_model_dataset_combinations(dataset_names)\n",
    "\n",
    "    todo_combis = []\n",
    "\n",
    "    for dataset_name, model_name in all_combis:\n",
    "        left_over = how_many_left_to_do(dataset_name, model_name + \"-\" + get_loss_postfix(sumo), total_todo=total_todo)\n",
    "\n",
    "        if left_over > 0:\n",
    "            todo_combis.append((dataset_name, model_name))\n",
    "\n",
    "    return todo_combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e3da4-9a87-4cda-81ff-10390a7b292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_worker(dataset_names, sumo):\n",
    "    while True:\n",
    "        todo_combis = get_todo_model_dataset_combinations(dataset_names, sumo=sumo)\n",
    "\n",
    "        if len(todo_combis) <= 0:\n",
    "            return\n",
    "\n",
    "        dataset_name, model_name = random.choice(todo_combis)\n",
    "        get_model = get_model_getters()[model_name]\n",
    "        print(f\"{dataset_name=}, {model_name=}\")\n",
    "        run_training(dataset_name, get_model, sumo=sumo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80fdc50-b1df-4276-ac06-7077f4e0bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cpu_worker(sumo):\n",
    "    run_worker([\"gbsg2\", \"recur\", \"lymph\", \"california\"], sumo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b1f6f-61f6-4cbc-a120-788321acf3a4",
   "metadata": {},
   "source": [
    "## Run the trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3f05c-7b77-4794-868f-927fa5a440fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_with_sumo_loss in [False, True]:\n",
    "    run_cpu_worker(sumo=train_with_sumo_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee89f8-9281-4d16-9797-b8bf5ccc5c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
