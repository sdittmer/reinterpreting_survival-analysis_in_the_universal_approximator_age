{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfa6fa-84fd-4f66-9756-c500de1e17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbimporter\n",
    "\n",
    "root = os.getcwd().split(\"survival_analysis\")[0]\n",
    "os.chdir(root + \"survival_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d7553-b97e-4f49-928f-6a67010b628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import CoxPHFitter, WeibullAFTFitter, LogLogisticAFTFitter, LogNormalAFTFitter, KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4e793-3147-4244-a1e5-74143db97333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_and_preprocessing.dfs_generator import Gbsg2Generator, RecurGenerator, LymphGenerator, CaliforniaHousingGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e85e91a",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125292f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name, data):\n",
    "    with open(f'trained_models/{df_generator.name}/{name}.pickle', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def save_model(name, model):\n",
    "    data = {\n",
    "        \"name\": name,\n",
    "        \"max_horizon\": df_generator.max_horizon,\n",
    "        \"model\": model,\n",
    "    }\n",
    "    save(name, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f0328-fbed-424c-9be1-71530d24e0ec",
   "metadata": {},
   "source": [
    "## KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad591833-f61f-427e-bede-804486a8ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KaplanMeierFitter():\n",
    "    model = KaplanMeierFitter()\n",
    "\n",
    "    model.fit(\n",
    "        durations=dfs[\"train\"].duration.copy(),\n",
    "        event_observed=dfs[\"train\"].event_observed.copy(),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6c340",
   "metadata": {},
   "source": [
    "## CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429944b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CoxPHFitter(**kwargs):\n",
    "    model = CoxPHFitter(**kwargs)\n",
    "\n",
    "    model.fit(\n",
    "        df=dfs[\"train\"].copy(),\n",
    "        duration_col=\"duration\",\n",
    "        event_col=\"event_observed\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbc01d",
   "metadata": {},
   "source": [
    "## WeibullAFTFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc972d-6c20-4560-9a6b-8061966f557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WeibullAFTFitter():\n",
    "    model = WeibullAFTFitter()\n",
    "\n",
    "    model.fit(\n",
    "        df=dfs[\"train\"].copy(),\n",
    "        duration_col=\"duration\",\n",
    "        event_col=\"event_observed\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b64ec2",
   "metadata": {},
   "source": [
    "## LogLogisticAFTFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c63c9d-76c3-4ff6-8b07-4e550faae68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LogLogisticAFTFitter():\n",
    "    model = LogLogisticAFTFitter()\n",
    "\n",
    "    model.fit(\n",
    "        df=dfs[\"train\"].copy(),\n",
    "        duration_col=\"duration\",\n",
    "        event_col=\"event_observed\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083ad65",
   "metadata": {},
   "source": [
    "## LogNormalAFTFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ac3d6-4790-42b3-aaa2-313db5e605c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LogNormalAFTFitter():\n",
    "    model = LogNormalAFTFitter()\n",
    "\n",
    "    model.fit(\n",
    "        df=dfs[\"train\"].copy(),\n",
    "        duration_col=\"duration\",\n",
    "        event_col=\"event_observed\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b355f-f325-4fb4-97b0-77db6835dabd",
   "metadata": {},
   "source": [
    "## Start all applicable trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5271e5-9702-412f-af2d-48ab0897fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(resolution=10):\n",
    "    km = get_KaplanMeierFitter()\n",
    "    save_model(\"KaplanMeier\", km)\n",
    "\n",
    "    print(\"\\t Weibull\")\n",
    "    weibull = get_WeibullAFTFitter()\n",
    "    save_model(\"Weibull\", weibull)\n",
    "\n",
    "    print(\"\\t LogLogistic\")\n",
    "    log_logistic = get_LogLogisticAFTFitter()\n",
    "    save_model(\"LogLogistic\", log_logistic)\n",
    "\n",
    "    print(\"\\t LogNormal\")\n",
    "    log_normal = get_LogNormalAFTFitter()\n",
    "    save_model(\"LogNormal\", log_normal)\n",
    "\n",
    "    print(\"\\t Cox_spline\")\n",
    "    cox = get_CoxPHFitter(baseline_estimation_method=\"spline\", n_baseline_knots=2)\n",
    "    save_model(\"Cox_spline\", cox)\n",
    "    cox.baseline_survival_.plot()\n",
    "    pd.DataFrame(cox.params_).T\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\t Cox_piecewise\")\n",
    "    cox = get_CoxPHFitter(\n",
    "        baseline_estimation_method=\"piecewise\",\n",
    "        breakpoints=np.linspace(0, df_generator.max_horizon, resolution+1)[1:],\n",
    "        penalizer=0.00\n",
    "    )\n",
    "    save_model(\"Cox_piecewise\", cox)\n",
    "    cox.baseline_survival_.plot()\n",
    "    pd.DataFrame(cox.params_).T\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0b7c5",
   "metadata": {},
   "source": [
    "# Load data & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0131bb0-1fa5-425f-8689-08deeb36a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"gbsg2\", \"recur\", \"lymph\", \"california\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c43cb0-bfad-4cfc-a073-605170f4d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(f\"Starting lifelines trainings for {dataset_name}.\")\n",
    "    pathlib.Path(f'trained_models/{dataset_name}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_generator = pickle.load(open(f\"data_and_preprocessing/df_generator_{dataset_name}.pickle\", \"rb\" ))\n",
    "    dfs = df_generator(horizon=None)\n",
    "\n",
    "    for part, df in dfs.items():\n",
    "        print(part, df.shape)\n",
    "\n",
    "    train_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f6d615-e256-4013-a112-86285e7e7d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
