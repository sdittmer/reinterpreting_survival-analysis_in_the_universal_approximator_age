{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348589b9-ce59-48a8-8992-f0db91691ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbimporter\n",
    "\n",
    "root = os.getcwd().split(\"survival_analysis\")[0]\n",
    "os.chdir(root + \"survival_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95b1e5-81a6-4bac-a4c6-1bec56f1411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f921e7-df24-4ac3-94c1-663417c78698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.get_tensors_of_df import get_tensors_of_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770ac95",
   "metadata": {},
   "source": [
    "# SampleTimesAndLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe17c9-543f-41e9-a203-fe2b17de507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleTimesAndLabels:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _sample_times_and_labels(self, durations, event_observeds, horizon):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def __call__(self, durations, event_observeds, horizon):\n",
    "        return self._sample_times_and_labels(durations, event_observeds, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2be7d1-8499-412e-8945-ad209db75590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleTimesAndLabelsDelta(SampleTimesAndLabels):\n",
    "\n",
    "    def _sample_times_and_labels(self, durations, event_observeds, horizon):\n",
    "        ts = durations.clone().view(len(durations), 1)\n",
    "        alives = 1 - event_observeds.clone().type(ts.dtype)\n",
    "\n",
    "        assert ts.shape == (len(durations), 1), f\"{ts.shape=} has a bad shape.\"\n",
    "        assert durations.shape == ts.shape, f\"Different shapes. {durations.shape=} != {ts.shape=}\"\n",
    "        assert alives.shape == ts.shape, f\"Different shapes. {alives.shape=} != {ts.shape=}\"\n",
    "        return ts, alives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84861e4f-b83c-4e3e-8657-ed521dd8f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleTimesAndLabelsGaussianDelta(SampleTimesAndLabels):\n",
    "\n",
    "    def __init__(self, σ):\n",
    "        self._σ = σ\n",
    "\n",
    "\n",
    "    def _sample_times_and_labels(self, durations, event_observeds, horizon):\n",
    "        η = torch.randn(len(durations), 1) * self._σ\n",
    "        ts = durations + η\n",
    "\n",
    "        ts[~event_observeds] = durations[~event_observeds]\n",
    "        ts = ts.clamp(0)\n",
    "\n",
    "        alives = (ts < durations) | ~event_observeds\n",
    "\n",
    "        assert durations.shape == ts.shape\n",
    "        return ts, alives.type(ts.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab0eaa",
   "metadata": {},
   "source": [
    "# Criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1ed2a-1e01-4778-ace6-3ac7c0820e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCELoss:\n",
    "\n",
    "    def __init__(self, σ_gaussian_delta, weight=1, label_smoothing=1e-3):\n",
    "        super().__init__()\n",
    "        self.my_weight = weight\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "        self.sample_times_and_labels = SampleTimesAndLabelsGaussianDelta(σ=σ_gaussian_delta)\n",
    "\n",
    "        assert 0 <= self.my_weight <= 1, f\"{self.my_weight=} is not in the interval [0, 1].\"\n",
    "\n",
    "\n",
    "    def _get_weights(self, targets):\n",
    "        targets_binary = targets > .5\n",
    "        weight = torch.ones_like(targets) * (1 - self.my_weight)\n",
    "        weight[~targets_binary] = self.my_weight\n",
    "        assert torch.all((0 <= weight) & (weight <= 1)), \"BCE weights outside [0, 1].\"\n",
    "        return weight\n",
    "\n",
    "\n",
    "    def __call__(self, outputs, targets, ts):\n",
    "        targets = torch.clamp(targets, self.label_smoothing, 1 - self.label_smoothing)\n",
    "        outputs.data.clamp_(self.label_smoothing, 1 - self.label_smoothing)\n",
    "\n",
    "        weight = self._get_weights(targets)\n",
    "\n",
    "        loss = torch.nn.functional.binary_cross_entropy(\n",
    "            outputs,\n",
    "            targets,\n",
    "            weight=weight,\n",
    "            size_average=None,\n",
    "            reduce=None,\n",
    "            reduction='mean'\n",
    "        )\n",
    "\n",
    "        assert torch.all(-1e-2 <= outputs), f\"Too small values in outputs. {outputs[0 > outputs]=}\"\n",
    "        assert torch.all(outputs <= 1), \"Too large values in outputs.\"\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88655b93-4ff2-4e8c-aa9c-e30b38f61c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuMoLoss:\n",
    "\n",
    "    def __init__(self, weight=1, label_smoothing=1e-3):\n",
    "        super().__init__()\n",
    "        self.my_weight = weight\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "        self.sample_times_and_labels = SampleTimesAndLabelsDelta()\n",
    "\n",
    "\n",
    "    def _get_δS(self, S_t, ts):\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=S_t,\n",
    "            inputs=ts,\n",
    "            grad_outputs=torch.ones_like(S_t),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "        return grads\n",
    "\n",
    "\n",
    "    def _get_f(self, S_t, ts):\n",
    "        grads = self._get_δS(S_t, ts)\n",
    "\n",
    "        f = -grads\n",
    "\n",
    "        f[torch.isnan(f) & (S_t < 1e-3)] = 0.\n",
    "\n",
    "        assert grads.shape == S_t.shape, f\"Shapes don't match: {grads.shape=} {S_t.shape=}\"\n",
    "        assert not torch.any(torch.isnan(f)), f\"f has NaNs, {f[torch.isnan(f)]=}, {S_t[torch.isnan(f)]=}, {ts[torch.isnan(f)]=}\"\n",
    "        assert torch.all(f >= -0.1), f\"f is negative. {f[f < 0]=}, {S_t[f < 0]=}\"\n",
    "        return f\n",
    "\n",
    "\n",
    "    def _get_f_ll(self, f, alives, ε=1e-16):\n",
    "        alives_binary = alives > 0.5\n",
    "        f_ll = torch.log(f[~alives_binary].clamp(ε)).clamp(-10).sum() * self.my_weight\n",
    "        return f_ll\n",
    "\n",
    "\n",
    "    def _get_S_ll(self, S, alives, ε=1e-16):\n",
    "        alives_binary = alives > 0.5\n",
    "        S_ll = torch.log(S[alives_binary].clamp(ε)).clamp(-10).sum()\n",
    "        return S_ll\n",
    "\n",
    "\n",
    "    def __call__(self, outputs, alives, ts):\n",
    "        f = self._get_f(outputs, ts)\n",
    "        S = outputs\n",
    "\n",
    "        f_ll = self._get_f_ll(f, alives)\n",
    "        S_ll = self._get_S_ll(f, alives)\n",
    "\n",
    "        loss = -(f_ll + S_ll) / len(outputs)\n",
    "\n",
    "        assert not torch.any(torch.isnan(S)), f\"Found NaN in outputs. {f[torch.isnan(S)]=}, {S_t[torch.isnan(S)]=}, {ts[torch.isnan(S)]=}\"\n",
    "        assert torch.all(-1e-2 <= S), f\"Too small values in outputs. {f[S_t < 0]=}, {S_t[S_t < 0]=}\"\n",
    "        assert torch.all(S <= 1), \"Too large values in outputs.\"\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5924ce31-478d-47a8-b02f-0c6d27b0e8b3",
   "metadata": {},
   "source": [
    "# TorchDfHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a28cad-8440-4862-850c-79fe8e37876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDfHandler:\n",
    "\n",
    "    def __init__(self, df_generator, part, sample_times_and_labels, adjust, horizon=None):\n",
    "        if horizon is None:\n",
    "            assert not adjust, f\"{horizon=}, but {adjust=}.\"\n",
    "\n",
    "        self._df_generator = df_generator\n",
    "        self._part = part\n",
    "        self._horizon = df_generator.max_horizon if horizon is None else horizon\n",
    "\n",
    "        dfs = df_generator(horizon=horizon, adjust=adjust)\n",
    "        df = dfs[part].copy()\n",
    "\n",
    "        self._df = self._check_and_clean_df(df)\n",
    "        self._df_generator.check_that_column_names_are_valid(self._df)\n",
    "        self._features, self._durations, self._event_observeds = self._get_tensors_of_df()\n",
    "\n",
    "        self.sample_times_and_labels = sample_times_and_labels\n",
    "\n",
    "\n",
    "    @property\n",
    "    def df_generator(self):\n",
    "        return self._df_generator\n",
    "\n",
    "\n",
    "    @property\n",
    "    def horizon(self):\n",
    "        return self._horizon\n",
    "\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "\n",
    "\n",
    "    def _check_and_clean_df(self, df):\n",
    "        columns = list(df.columns)\n",
    "        df = df[columns]\n",
    "\n",
    "        assert \"duration\" in columns, f\"No 'duration' in {columns=}\"\n",
    "        assert \"event_observed\" in columns, f\"No 'event_observed' in {columns=}\"\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _get_tensors_of_df(self):\n",
    "        return get_tensors_of_df(df=self._df)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def n_input_features(self):\n",
    "        assert len(self._features.shape) == 2\n",
    "        return self._features.shape[1]\n",
    "\n",
    "\n",
    "    def sample_batch(self, n_samples):\n",
    "        features, durations, event_observeds = self()\n",
    "\n",
    "        idxs = np.random.randint(0, len(features), size=n_samples)\n",
    "\n",
    "        features = features[idxs]\n",
    "        durations = durations[idxs]\n",
    "        event_observeds = event_observeds[idxs]\n",
    "        return features, durations, event_observeds\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        return self._features, self._durations, self._event_observeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953013d9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2c3fc-09a7-4719-8c9c-2973d59d2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59834f00-16ea-4752-9faf-1e97cbd9c2fa",
   "metadata": {},
   "source": [
    "## BestModelMemorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161189d-5923-4056-a6bf-c131f14bed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModelMemorizer:\n",
    "\n",
    "    def __init__(self, model_via_moving_average_on_validation, patience_factor):\n",
    "        self.model_via_moving_average_on_validation = model_via_moving_average_on_validation\n",
    "\n",
    "        self._best_model = None\n",
    "        self._selected_epoch = np.inf\n",
    "        self._best_val_score = np.inf\n",
    "        self._likely_best_found = False\n",
    "        self._patience_factor = patience_factor\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        return self._best_model, self._selected_epoch, self._best_val_score\n",
    "\n",
    "\n",
    "    def log(self, losses_valid, model):\n",
    "        no_best_model_selection = self.model_via_moving_average_on_validation is None\n",
    "\n",
    "        if no_best_model_selection:\n",
    "            self._best_model = copy.deepcopy(model)\n",
    "            self._selected_epoch = len(losses_valid)\n",
    "            self._best_val_score = np.mean(losses_valid)\n",
    "            return\n",
    "\n",
    "        warm_up_phase = self.model_via_moving_average_on_validation > len(losses_valid)\n",
    "\n",
    "        if warm_up_phase:\n",
    "            self._best_model = copy.deepcopy(model)\n",
    "            self._selected_epoch = len(losses_valid)\n",
    "            self._best_val_score = np.inf\n",
    "            return\n",
    "\n",
    "        mova_val_loss = moving_average(losses_valid, n=self.model_via_moving_average_on_validation)[-1]\n",
    "\n",
    "        if mova_val_loss < self._best_val_score:\n",
    "            self._best_val_score = mova_val_loss\n",
    "            self._best_model = copy.deepcopy(model)\n",
    "            self._selected_epoch = len(losses_valid)\n",
    "            return\n",
    "\n",
    "        patience = self.model_via_moving_average_on_validation * self._patience_factor\n",
    "        ran_out_of_patience = self._selected_epoch < len(losses_valid) - patience\n",
    "\n",
    "        if ran_out_of_patience:\n",
    "            self._likely_best_found = True\n",
    "\n",
    "\n",
    "    @property\n",
    "    def likely_best_found(self):\n",
    "        return self._likely_best_found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6036c1b-2c3f-4830-8d71-8f0c2bc70340",
   "metadata": {},
   "source": [
    "## TrainingPlotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81745efa-904c-49dc-8b4c-0e5e6428ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPlotting:\n",
    "\n",
    "    def plot_losses(losses_train, losses_valid, n_mova):\n",
    "        plt.plot(\n",
    "            range(n_mova-1, len(losses_train)),\n",
    "            moving_average(losses_train, n=n_mova),\n",
    "            label=\"train mova\"\n",
    "        )\n",
    "\n",
    "        plt.plot(\n",
    "            range(n_mova-1, len(losses_valid)),\n",
    "            moving_average(losses_valid, n=n_mova),\n",
    "            label=\"valid mova\"\n",
    "        )\n",
    "\n",
    "        plt.title(moving_average(losses_valid, n=n_mova).min())\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_some_survival_curves(model, df_handler_valid):\n",
    "        horizon = df_handler_valid.horizon\n",
    "\n",
    "        for i in range(3 * 6):\n",
    "            plt.subplot(3, 6, i + 1)\n",
    "\n",
    "            device = next(model.parameters()).device\n",
    "            model.eval()\n",
    "\n",
    "            features, durations, event_observeds = df_handler_valid.sample_batch(1)\n",
    "            multi_features = torch.cat([features]*64, dim=0).to(device)\n",
    "\n",
    "            ts = torch.linspace(0, horizon, 64, device=device).view(-1, 1)\n",
    "            S_ts = model(xs=multi_features, ts=ts)\n",
    "\n",
    "            plt.plot(ts.flatten().detach().cpu().numpy(), S_ts.flatten().detach().cpu().numpy())\n",
    "\n",
    "            if event_observeds.item():\n",
    "                plt.vlines(durations.item(), 0, 1, 'r')\n",
    "\n",
    "            if not event_observeds.item():\n",
    "                plt.vlines(durations.item(), 0, 1, 'b')\n",
    "\n",
    "            plt.ylim(0, 1)\n",
    "\n",
    "        model.train()\n",
    "        plt.gcf().set_size_inches(35, 10)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ceb22-5089-490b-b147-c5c2db81a27f",
   "metadata": {},
   "source": [
    "## NetTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c44df-e030-464a-af1d-7022747de447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTrainer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_generator,\n",
    "        criterion,\n",
    "        n_training_steps=200000,\n",
    "        batch_size=32,\n",
    "        lr=1e-3,\n",
    "        weight_decay=0,\n",
    "        model_via_moving_average_on_validation=512,\n",
    "        patience_factor=5,\n",
    "        adjust=False,\n",
    "        clip=None,\n",
    "    ):\n",
    "        assert model_via_moving_average_on_validation is not None, \"model_via_moving_average_on_validation is None\"\n",
    "\n",
    "        self.horizon = df_generator.max_horizon\n",
    "        self.df_generator = df_generator\n",
    "        self.adjust = adjust\n",
    "        self.clip = clip\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self._patience_factor = patience_factor\n",
    "\n",
    "        self.model_via_moving_average_on_validation = model_via_moving_average_on_validation\n",
    "\n",
    "        self.df_handler_valid = self._get_df_handler(\"valid\")\n",
    "\n",
    "\n",
    "    @property\n",
    "    def n_input_features(self):\n",
    "        return self.df_handler_valid.n_input_features\n",
    "\n",
    "\n",
    "    def _get_df_handler(self, part, horizon=None):\n",
    "        adjust = False if horizon is None else self.adjust\n",
    "\n",
    "        handler = TorchDfHandler(\n",
    "            df_generator=self.df_generator,\n",
    "            part=part,\n",
    "            sample_times_and_labels=self.criterion.sample_times_and_labels,\n",
    "            adjust=adjust,\n",
    "            horizon=horizon,\n",
    "        )\n",
    "        return handler\n",
    "\n",
    "\n",
    "    def get_loss_on_random_batch(self, model, df_handler):\n",
    "        features, durations, event_observeds = df_handler.sample_batch(self.batch_size)\n",
    "        ts, alives = df_handler.sample_times_and_labels(durations, event_observeds, horizon=self.horizon)\n",
    "\n",
    "        preds = model(xs=features, ts=ts)\n",
    "        loss = self.criterion(preds, alives, ts=ts)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def _eval_current_model(self, model, losses_valid, best_model_memorizer, df_handler_valid):\n",
    "        model.eval()\n",
    "        loss = self.get_loss_on_random_batch(model=model, df_handler=df_handler_valid)\n",
    "        losses_valid.append(loss.item())\n",
    "        best_model_memorizer.log(losses_valid=losses_valid, model=model)\n",
    "        model.train()\n",
    "\n",
    "\n",
    "    def _get_best_model_memorizer(self):\n",
    "        best_model_memorizer = BestModelMemorizer(\n",
    "            model_via_moving_average_on_validation=self.model_via_moving_average_on_validation,\n",
    "            patience_factor=self._patience_factor\n",
    "        )\n",
    "        return best_model_memorizer\n",
    "\n",
    "\n",
    "    def _train_step(self, optimizer, loss, model):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if self.clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), self.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    def train_model(self, model):\n",
    "        best_model_memorizer = self._get_best_model_memorizer()\n",
    "\n",
    "        df_handler_train = self._get_df_handler(part=\"train\")\n",
    "        df_handler_valid = self._get_df_handler(part=\"valid\")\n",
    "\n",
    "        losses_train, losses_valid = [], []\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        model.train()\n",
    "\n",
    "        for _ in tqdm(range(self.n_training_steps)):\n",
    "            loss = self.get_loss_on_random_batch(model=model, df_handler=df_handler_train)\n",
    "            losses_train.append(loss.item())\n",
    "\n",
    "            self._train_step(optimizer, loss, model)\n",
    "            self._eval_current_model(model, losses_valid, best_model_memorizer, df_handler_valid)\n",
    "\n",
    "            if best_model_memorizer.likely_best_found:\n",
    "                print(f\"Stoped training at step {len(losses_valid)}.\")\n",
    "                break\n",
    "\n",
    "        model.eval()\n",
    "        model, selected_epoch, best_val_score = best_model_memorizer()\n",
    "        return model, losses_train, losses_valid, selected_epoch, best_val_score\n",
    "\n",
    "\n",
    "    def _get_model_dict(self, name, model):\n",
    "        model_dict = {\n",
    "            \"model\": model,\n",
    "            \"name\": name,\n",
    "            \"max_horizon\": self.horizon,\n",
    "        }\n",
    "        return model_dict\n",
    "\n",
    "\n",
    "    def _save(self, name, data):\n",
    "        with open(f'trained_models/{self.df_handler_valid.df_generator.name}/{name}.pickle', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "\n",
    "    def train_and_save(self, name, model, verbose=True, save=True):\n",
    "        model, losses_train, losses_valid, selected_epoch, best_val_score = self.train_model(model)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{selected_epoch=}\")\n",
    "            TrainingPlotting.plot_losses(losses_train, losses_valid, n_mova=self.model_via_moving_average_on_validation)\n",
    "            TrainingPlotting.plot_some_survival_curves(model, self.df_handler_valid)\n",
    "\n",
    "        model_dict = self._get_model_dict(name, model)\n",
    "        if save:\n",
    "            self._save(name, model_dict)\n",
    "        return model, best_val_score, model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d35384-ca5d-4eb2-a507-f8db14a10f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
